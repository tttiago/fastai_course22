{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previously I've shown how to create a [linear model and neural net from scratch](https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch), and used it to create a solid submission to Kaggle's [Titanic](https://www.kaggle.com/competitions/titanic/) competition. However, for *tabular* data (i.e data that looks like spreadsheet or database tables, such as the data for the Titanic competition) it's more common to see good results by using ensembles of decision trees, such as Random Forests and Gradient Boosting Machines.\n",
    "\n",
    "In this notebook, we're going to learn all about Random Forests, by building one from scratch, and using it to submit to the Titanic competition! That might sound like a pretty big stretch, but I think you'll be surprised to discover how straightforward it actually is.\n",
    "\n",
    "We'll start by importing the basic set of libraries we normally need for data science work, and setting numpy to use our display space more efficiently:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "np.set_printoptions(linewidth=140)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create `DataFrame`s from the CSV files just like we did in the \"*linear model and neural net from scratch*\" notebook, and do much the same preprocessing (so go back and check that out if you're not already familiar with the dataset):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "iskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n",
    "if iskaggle: path = Path('../input/titanic')\n",
    "else:\n",
    "    path = path = Path.home()/'titanic'\n",
    "    if not path.exists():\n",
    "        import zipfile, kaggle\n",
    "        kaggle.api.competition_download_cli(path.name, path=path)\n",
    "        zipfile.ZipFile(f'{path}/{path.name}.zip').extractall(path)\n",
    "\n",
    "df = pd.read_csv(path/'train.csv')\n",
    "tst_df = pd.read_csv(path/'test.csv')\n",
    "modes = df.mode().iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One difference with Random Forests however is that we don't generally have to create *dummy variables* like we did for non-numeric columns in the linear models and neural network. Instead, we can just convert those fields to *categorical variables*, which internally in Pandas makes a list of all the unique values in the column, and replaces each value with a number. The number is just an index for looking up the value in the list of all unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def proc_data(df):\n",
    "    df.fillna(modes, inplace=True)\n",
    "    df['LogFare'] = np.log1p(df['Fare'])\n",
    "    df['Embarked'] = pd.Categorical(df.Embarked)\n",
    "    df['Sex'] = pd.Categorical(df.Sex)\n",
    "    \n",
    "proc_data(df)\n",
    "proc_data(tst_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll make a list of the continuous, categorical, and dependent variables. Note that we no longer consider `Pclass` a categorical variable. That's because it's *ordered* (i.e 1st, 2nd, and 3rd class have an order), and decision trees, as we'll see, only care about order, not about absolute value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['Sex', 'Embarked']\n",
    "conts = ['Age', 'SibSp', 'Parch', 'LogFare', 'Pclass']\n",
    "dep = 'Survived'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even although we've made the `cats` columns categorical, they are still shown by Pandas as their original values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      male\n",
       "1    female\n",
       "2    female\n",
       "3    female\n",
       "4      male\n",
       "Name: Sex, dtype: category\n",
       "Categories (2, object): ['female', 'male']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sex.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However behind the scenes they're now stored as integers, with indices that are looked up in the `Categories` list shown in the output above. We can view the stored values by looking in the `cat.codes` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    1\n",
       "dtype: int8"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sex.cat.codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we create a Random Forest or Gradient Boosting Machine, we'll first need to learn how to create a *decision tree*, from which both of these models are built.\n",
    "\n",
    "And to create a decision tree, we'll first need to create a *binary split*, since that's what a decision tree is built from.\n",
    "\n",
    "A binary split is where all rows are placed into one of two groups, based on whether they're above or below some threshold of some column. For example, we could split the rows of our dataset into males and females, by using the threshold `0.5` and the column `Sex` (since the values in the column are `0` for `female` and `1` for `male`). We can use a plot to see how that would split up our data -- we'll use the [Seaborn](https://seaborn.pydata.org/) library, which is a layer on top of [matplotlib](https://matplotlib.org/) that makes some useful charts easier to create, and more aesthetically pleasing by default:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 792x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(11, 5))\n",
    "sns.barplot(data=df, y=dep, x='Sex', ax=axes[0]).set(title='Survival rate')\n",
    "sns.countplot(data=df, x='Sex', ax=axes[1]).set(title='Sex distribution');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that (on the left) if we split the data into males and females, we'd have groups that have very different survival rates: >70% for females, and <20% for males. We can also see (on the right) that the split would be reasonably even, with over 300 passengers (out of around 900) in each group.\n",
    "\n",
    "We could create a very simple \"model\" which simply says that all females survive, and no males do. To do so, we better first split our data into a training and validation set, to see how accurate this approach turns out to be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random.seed(42)\n",
    "trn_df, val_df = train_test_split(df, test_size=0.25)\n",
    "trn_df[cats] = trn_df[cats].apply(lambda x: x.cat.codes)\n",
    "val_df[cats] = val_df[cats].apply(lambda x: x.cat.codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(In the previous step we also replaced the categorical variables with their integer codes, since some of the models we'll be building in a moment require that.)\n",
    "\n",
    "Now we can create our independent variables (the `x` variables) and dependent (the `y` variable):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xs_y(df):\n",
    "    xs = df[cats+conts].copy()\n",
    "    return xs, df[dep] if dep in df else None\n",
    "\n",
    "trn_xs, trn_y = xs_y(trn_df)\n",
    "val_xs, val_y = xs_y(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's the predictions for our extremely simple model, where `female` is coded as `0`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = val_xs.Sex==0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use mean absolute error to measure how good this model is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21524663677130046"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "mean_absolute_error(val_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we could try splitting on a continuous column. We have to use a somewhat different chart to see how this might work -- here's an example of how we could look at `LogFare`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 792x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_fare = trn_df[trn_df.LogFare>0]\n",
    "fig, axes = plt.subplots(1, 2, figsize=(11, 5))\n",
    "sns.boxenplot(data=df_fare, x=dep, y='LogFare', ax=axes[0])\n",
    "sns.kdeplot(data=df_fare, x='LogFare', ax=axes[1]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [boxenplot](https://seaborn.pydata.org/generated/seaborn.boxenplot.html) above shows quantiles of `LogFare` for each group of `Survived==0` and `Survived==1`. It shows that the median `LogFare` for passengers that didn't survive is around `2.5`, and for those that did it's around `3.2`. So it seems that people that paid more for their tickets were more likely to get put on a lifeboat.\n",
    "\n",
    "Let's create a simple model based on this observation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = val_xs.LogFare > 2.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and test it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.336322869955157"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(val_y, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is quite a bit less accurate than our model that used `Sex` as the single binary split.\n",
    "\n",
    "Ideally, we'd like some way to try more columns and breakpoints more easily. We could create a function that returns how good our model is, in order to more quickly try out a few different splits. We'll create a `score` function to do this. Instead of returning the mean absolute error, we'll calculate a measure of *impurity* -- that is, how much the binary split creates two groups where the rows in a group are each similar to each other, or dissimilar.\n",
    "\n",
    "We can measure the similarity of rows inside a group by taking the standard deviation of the dependent variable. If it's higher, then it means the rows are more different to each other. We'll then multiply this by the number of rows, since a bigger group as more impact than a smaller group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(229, 439)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lhs = trn_xs['Sex'] <= 0.5\n",
    "tot1, tot2 = lhs.sum(), (~lhs).sum()\n",
    "tot1, tot2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40787530982063946"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(trn_y[lhs].std() * tot1 + trn_y[~lhs].std() * tot2)/(len(trn_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _side_score(side, y):\n",
    "    tot = side.sum()\n",
    "    if tot <= 1: return 0\n",
    "    return y[side].std() * tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've got that written, we can calculate the score for a split by adding up the scores for the \"left hand side\" (lhs) and \"right hand side\" (rhs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(col, y, split):\n",
    "    lhs = col <= split\n",
    "    return(_side_score(lhs, y) + _side_score(~lhs, y))/len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For instance, here's the impurity score for the split on `Sex`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40787530982063946"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(trn_xs['Sex'], trn_y, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and for `LogFare`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47180873952099694"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score(trn_xs['LogFare'], trn_y, 2.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we'd expect from our earlier tests, `Sex` appears to be a better split.\n",
    "\n",
    "To make it easier to find the best binary split, we can create a simple interactive tool (note that this only works in Kaggle if you click \"Copy and Edit\" in the top right to open the notebook editor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed90e8b8df664782985b9d745f3b79bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='nm', options=('Age', 'SibSp', 'Parch', 'LogFare', 'Pclass'), value"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def iscore(nm, split):\n",
    "    col = trn_xs[nm]\n",
    "    return score(col, trn_y, split)\n",
    "\n",
    "from ipywidgets import interact\n",
    "interact(nm=conts, split=15.5)(iscore);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try selecting different columns and split points using the dropdown and slider above. What splits can you find that increase the purity of the data?\n",
    "\n",
    "We can do the same thing for the categorical variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca9c1b07e33c493e9e585d8dbee4335c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='nm', options=('Sex', 'Embarked'), value='Sex'), IntSlider(value=2,"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.iscore(nm, split)>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(nm=cats, split=2)(iscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That works well enough, but it's rather slow and fiddly. Perhaps we could get the computer to automatically find the best split point for a column for us? For example, to find the best split point for `age` we'd first need to make a list of all the possible split points (i.e all the unique values of that field)...:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42,  0.67,  0.75,  0.83,  0.92,  1.  ,  2.  ,  3.  ,  4.  ,  5.  ,  6.  ,  7.  ,  8.  ,  9.  , 10.  , 11.  , 12.  , 13.  , 14.  ,\n",
       "       14.5 , 15.  , 16.  , 17.  , 18.  , 19.  , 20.  , 21.  , 22.  , 23.  , 24.  , 24.5 , 25.  , 26.  , 27.  , 28.  , 28.5 , 29.  , 30.  ,\n",
       "       31.  , 32.  , 32.5 , 33.  , 34.  , 34.5 , 35.  , 36.  , 36.5 , 37.  , 38.  , 39.  , 40.  , 40.5 , 41.  , 42.  , 43.  , 44.  , 45.  ,\n",
       "       45.5 , 46.  , 47.  , 48.  , 49.  , 50.  , 51.  , 52.  , 53.  , 54.  , 55.  , 55.5 , 56.  , 57.  , 58.  , 59.  , 60.  , 61.  , 62.  ,\n",
       "       64.  , 65.  , 70.  , 70.5 , 74.  , 80.  ])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nm = 'Age'\n",
    "col = trn_xs[nm]\n",
    "unq = col.unique()\n",
    "unq.sort()\n",
    "unq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and find which index of those values is where `score()` is the lowest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.0"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = np.array([score(col, trn_y, o) for o in unq if not np.isnan(o)])\n",
    "unq[scores.argmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, it looks like, for instance, that for the `Age` column, `6` is the optimal cutoff according to our training set.\n",
    "\n",
    "We can write a little function that implements this idea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.0, 0.478316717508991)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def min_col(df, nm):\n",
    "    col, y = df[nm], df[dep]\n",
    "    unq = col.dropna().unique()\n",
    "    scores = np.array([score(col, y, o) for o in unq])\n",
    "    idx = scores.argmin()\n",
    "    return unq[idx], scores[idx]\n",
    "\n",
    "min_col(trn_df, 'Age')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try all the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sex': (0, 0.40787530982063946),\n",
       " 'Embarked': (0, 0.47883342573147836),\n",
       " 'Age': (6.0, 0.478316717508991),\n",
       " 'SibSp': (4, 0.4783740258817434),\n",
       " 'Parch': (0, 0.4805296527841601),\n",
       " 'LogFare': (2.4390808375825834, 0.4620823937736597),\n",
       " 'Pclass': (2, 0.46048261885806596)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = cats + conts\n",
    "{o: min_col(trn_df, o) for o in cols}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to this, `Sex<=0` is the best split we can use.\n",
    "\n",
    "We've just re-invented the [OneR](https://link.springer.com/article/10.1023/A:1022631118932) classifier (or at least, a minor variant of it), which was found to be one of the most effective classifiers in real-world datasets, compared to the algorithms in use in 1993. Since it's so simple and surprisingly effective, it makes for a great *baseline* -- that is, a starting point that you can use to compare your more sophisticated models to.\n",
    "\n",
    "We found earlier that out OneR rule had an error of around `0.215`, so we'll keep that in mind as we try out more sophisticated approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How can we improve our OneR classifier, which predicts survival based only on `Sex`?\n",
    "\n",
    "How about we take each of our two groups, `female` and `male`, and create one more binary split for each of them. That is: fine the single best split for females, and the single best split for males. To do this, all we have to do is repeat the previous section's steps, once for males, and once for females.\n",
    "\n",
    "First, we'll remove `Sex` from the list of possible splits (since we've already used it, and there's only one possible split for that binary column), and create our two groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols.remove(\"Sex\")\n",
    "ismale = trn_df.Sex==1\n",
    "males,females = trn_df[ismale],trn_df[~ismale]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's find the single best binary split for males...:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Embarked': (0, 0.3875581870410906),\n",
       " 'Age': (6.0, 0.3739828371010595),\n",
       " 'SibSp': (4, 0.3875864227586273),\n",
       " 'Parch': (0, 0.3874704821461959),\n",
       " 'LogFare': (2.803360380906535, 0.3804856231758151),\n",
       " 'Pclass': (1, 0.38155442004360934)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{o:min_col(males, o) for o in cols}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and for females:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Embarked': (0, 0.4295252982857327),\n",
       " 'Age': (50.0, 0.4225927658431649),\n",
       " 'SibSp': (4, 0.42319212059713535),\n",
       " 'Parch': (3, 0.4193314500446158),\n",
       " 'LogFare': (4.256321678298823, 0.41350598332911376),\n",
       " 'Pclass': (2, 0.3335388911567601)}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{o:min_col(females, o) for o in cols}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best next binary split for males is `Age<=6`, and for females is `Pclass<=2`.\n",
    "\n",
    "By adding these rules, we have created a *decision tree*, where our model will first check whether `Sex` is female or male, and depending on the result will then check either the above `Age` or `Pclass` rules, as appropriate. We could then repeat the process, creating new additional rules for each of the four groups we've now created.\n",
    "\n",
    "Rather than writing that code manually, we can use `DecisionTreeClassifier`, from *sklearn*, which does exactly that for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "\n",
    "m = DecisionTreeClassifier(max_leaf_nodes=4).fit(trn_xs, trn_y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One handy feature or this class is that it provides a function for drawing a tree representing the rules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "\n",
    "def draw_tree(t, df, size=10, ratio=0.6, precision=2, **kwargs):\n",
    "    s=export_graphviz(t, out_file=None, feature_names=df.columns, filled=True, rounded=True,\n",
    "                      special_characters=True, rotate=False, precision=precision, **kwargs)\n",
    "    return graphviz.Source(re.sub('Tree {', f'Tree {{ size={size}; ratio={ratio}', s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"593pt\" height=\"358pt\"\n",
       " viewBox=\"0.00 0.00 592.50 358.40\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 354.4)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-354.4 588.5,-354.4 588.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f5ceb2\" stroke=\"black\" d=\"M352,-339C352,-339 227,-339 227,-339 221,-339 215,-333 215,-327 215,-327 215,-283 215,-283 215,-277 221,-271 227,-271 227,-271 352,-271 352,-271 358,-271 364,-277 364,-283 364,-283 364,-327 364,-327 364,-333 358,-339 352,-339\"/>\n",
       "<text text-anchor=\"start\" x=\"254.5\" y=\"-323.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Sex  0.5</text>\n",
       "<text text-anchor=\"start\" x=\"250\" y=\"-308.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.47</text>\n",
       "<text text-anchor=\"start\" x=\"236.5\" y=\"-293.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 668</text>\n",
       "<text text-anchor=\"start\" x=\"223\" y=\"-278.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [415, 253]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#7ebfee\" stroke=\"black\" d=\"M268.5,-199C268.5,-199 152.5,-199 152.5,-199 146.5,-199 140.5,-193 140.5,-187 140.5,-187 140.5,-143 140.5,-143 140.5,-137 146.5,-131 152.5,-131 152.5,-131 268.5,-131 268.5,-131 274.5,-131 280.5,-137 280.5,-143 280.5,-143 280.5,-187 280.5,-187 280.5,-193 274.5,-199 268.5,-199\"/>\n",
       "<text text-anchor=\"start\" x=\"167\" y=\"-183.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass  2.5</text>\n",
       "<text text-anchor=\"start\" x=\"171\" y=\"-168.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.38</text>\n",
       "<text text-anchor=\"start\" x=\"157.5\" y=\"-153.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 229</text>\n",
       "<text text-anchor=\"start\" x=\"148.5\" y=\"-138.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [59, 170]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M270.58,-270.95C259.76,-252.05 246.09,-228.17 234.52,-207.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"237.55,-206.2 229.54,-199.26 231.47,-209.68 237.55,-206.2\"/>\n",
       "<text text-anchor=\"middle\" x=\"222.98\" y=\"-219.69\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#eb9e67\" stroke=\"black\" d=\"M426.5,-199C426.5,-199 310.5,-199 310.5,-199 304.5,-199 298.5,-193 298.5,-187 298.5,-187 298.5,-143 298.5,-143 298.5,-137 304.5,-131 310.5,-131 310.5,-131 426.5,-131 426.5,-131 432.5,-131 438.5,-137 438.5,-143 438.5,-143 438.5,-187 438.5,-187 438.5,-193 432.5,-199 426.5,-199\"/>\n",
       "<text text-anchor=\"start\" x=\"333\" y=\"-183.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age  6.5</text>\n",
       "<text text-anchor=\"start\" x=\"329\" y=\"-168.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.31</text>\n",
       "<text text-anchor=\"start\" x=\"315.5\" y=\"-153.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 439</text>\n",
       "<text text-anchor=\"start\" x=\"306.5\" y=\"-138.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [356, 83]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;2 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>0&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M308.42,-270.95C319.24,-252.05 332.91,-228.17 344.48,-207.96\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"347.53,-209.68 349.46,-199.26 341.45,-206.2 347.53,-209.68\"/>\n",
       "<text text-anchor=\"middle\" x=\"356.02\" y=\"-219.69\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#40a0e6\" stroke=\"black\" d=\"M119,-62.5C119,-62.5 12,-62.5 12,-62.5 6,-62.5 0,-56.5 0,-50.5 0,-50.5 0,-21.5 0,-21.5 0,-15.5 6,-9.5 12,-9.5 12,-9.5 119,-9.5 119,-9.5 125,-9.5 131,-15.5 131,-21.5 131,-21.5 131,-50.5 131,-50.5 131,-56.5 125,-62.5 119,-62.5\"/>\n",
       "<text text-anchor=\"start\" x=\"26\" y=\"-47.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.06</text>\n",
       "<text text-anchor=\"start\" x=\"12.5\" y=\"-32.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 120</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-17.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 116]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;3 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M172.78,-130.96C151.11,-111.98 124,-88.24 102.46,-69.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"104.62,-66.61 94.79,-62.66 100.01,-71.88 104.62,-66.61\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#fffdfb\" stroke=\"black\" d=\"M268,-62.5C268,-62.5 161,-62.5 161,-62.5 155,-62.5 149,-56.5 149,-50.5 149,-50.5 149,-21.5 149,-21.5 149,-15.5 155,-9.5 161,-9.5 161,-9.5 268,-9.5 268,-9.5 274,-9.5 280,-15.5 280,-21.5 280,-21.5 280,-50.5 280,-50.5 280,-56.5 274,-62.5 268,-62.5\"/>\n",
       "<text text-anchor=\"start\" x=\"179.5\" y=\"-47.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"161.5\" y=\"-32.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 109</text>\n",
       "<text text-anchor=\"start\" x=\"157\" y=\"-17.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [55, 54]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;4 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>1&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M211.54,-130.96C212.1,-113.15 212.79,-91.14 213.37,-72.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"216.88,-72.76 213.69,-62.66 209.88,-72.54 216.88,-72.76\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#88c4ef\" stroke=\"black\" d=\"M414.5,-62.5C414.5,-62.5 316.5,-62.5 316.5,-62.5 310.5,-62.5 304.5,-56.5 304.5,-50.5 304.5,-50.5 304.5,-21.5 304.5,-21.5 304.5,-15.5 310.5,-9.5 316.5,-9.5 316.5,-9.5 414.5,-9.5 414.5,-9.5 420.5,-9.5 426.5,-15.5 426.5,-21.5 426.5,-21.5 426.5,-50.5 426.5,-50.5 426.5,-56.5 420.5,-62.5 414.5,-62.5\"/>\n",
       "<text text-anchor=\"start\" x=\"326\" y=\"-47.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.41</text>\n",
       "<text text-anchor=\"start\" x=\"317\" y=\"-32.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 21</text>\n",
       "<text text-anchor=\"start\" x=\"312.5\" y=\"-17.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [6, 15]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>2&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M367.72,-130.96C367.3,-113.15 366.78,-91.14 366.35,-72.9\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"369.84,-72.57 366.11,-62.66 362.84,-72.74 369.84,-72.57\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#ea995f\" stroke=\"black\" d=\"M572.5,-62.5C572.5,-62.5 456.5,-62.5 456.5,-62.5 450.5,-62.5 444.5,-56.5 444.5,-50.5 444.5,-50.5 444.5,-21.5 444.5,-21.5 444.5,-15.5 450.5,-9.5 456.5,-9.5 456.5,-9.5 572.5,-9.5 572.5,-9.5 578.5,-9.5 584.5,-15.5 584.5,-21.5 584.5,-21.5 584.5,-50.5 584.5,-50.5 584.5,-56.5 578.5,-62.5 572.5,-62.5\"/>\n",
       "<text text-anchor=\"start\" x=\"475\" y=\"-47.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.27</text>\n",
       "<text text-anchor=\"start\" x=\"461.5\" y=\"-32.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 418</text>\n",
       "<text text-anchor=\"start\" x=\"452.5\" y=\"-17.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [350, 68]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>2&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M406.48,-130.96C428.3,-111.98 455.6,-88.24 477.29,-69.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"479.76,-71.86 485.01,-62.66 475.16,-66.58 479.76,-71.86\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "draw_tree(m, trn_xs, size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that it's found exactly the same splits as we did!\n",
    "\n",
    "In this picture, the more orange nodes have a lower survival rate, and blue have higher survival. Each node shows how many rows (\"*samples*\") match that set of rules, and shows how many perish or survive (\"*values*\"). There's also something called \"*gini*\". That's another measure of impurity, and it's very similar to the `score()` we created earlier. It's defined as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gini(cond):\n",
    "    act = df.loc[cond, dep]\n",
    "    return 1 - act.mean()**2 - (1-act).mean()**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this calculates is the probability that, if you pick two rows from a group, you'll get the same `Survived` result each time. If the group is all the same, the probability is `1.0`, and `0.0` if they're all different:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3828350034484158, 0.3064437162277842)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gini(df.Sex=='female'), gini(df.Sex=='male')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how this model compares to our OneR version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2242152466367713"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(val_y, m.predict(val_xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a tiny bit worse. Since this is such a small dataset (we've only got around 200 rows in our validation set) this small difference isn't really meaningful. Perhaps we'll see better results if we create a bigger tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"1175pt\" height=\"708pt\"\n",
       " viewBox=\"0.00 0.00 1174.50 707.60\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 703.6)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-703.6 1170.5,-703.6 1170.5,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0</title>\n",
       "<path fill=\"#f5ceb2\" stroke=\"black\" d=\"M627.5,-698C627.5,-698 502.5,-698 502.5,-698 496.5,-698 490.5,-692 490.5,-686 490.5,-686 490.5,-642 490.5,-642 490.5,-636 496.5,-630 502.5,-630 502.5,-630 627.5,-630 627.5,-630 633.5,-630 639.5,-636 639.5,-642 639.5,-642 639.5,-686 639.5,-686 639.5,-692 633.5,-698 627.5,-698\"/>\n",
       "<text text-anchor=\"start\" x=\"530\" y=\"-682.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Sex  0.5</text>\n",
       "<text text-anchor=\"start\" x=\"525.5\" y=\"-667.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.47</text>\n",
       "<text text-anchor=\"start\" x=\"512\" y=\"-652.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 668</text>\n",
       "<text text-anchor=\"start\" x=\"498.5\" y=\"-637.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [415, 253]</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>1</title>\n",
       "<path fill=\"#7ebfee\" stroke=\"black\" d=\"M476,-591C476,-591 360,-591 360,-591 354,-591 348,-585 348,-579 348,-579 348,-535 348,-535 348,-529 354,-523 360,-523 360,-523 476,-523 476,-523 482,-523 488,-529 488,-535 488,-535 488,-579 488,-579 488,-585 482,-591 476,-591\"/>\n",
       "<text text-anchor=\"start\" x=\"374.5\" y=\"-575.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Pclass  2.5</text>\n",
       "<text text-anchor=\"start\" x=\"378.5\" y=\"-560.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.38</text>\n",
       "<text text-anchor=\"start\" x=\"365\" y=\"-545.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 229</text>\n",
       "<text text-anchor=\"start\" x=\"356\" y=\"-530.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [59, 170]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M518.49,-629.78C503.87,-619.33 487.59,-607.71 472.47,-596.91\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"474.38,-593.97 464.21,-591.01 470.31,-599.67 474.38,-593.97\"/>\n",
       "<text text-anchor=\"middle\" x=\"468.32\" y=\"-611.97\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 8 -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>8</title>\n",
       "<path fill=\"#eb9e67\" stroke=\"black\" d=\"M779,-591C779,-591 663,-591 663,-591 657,-591 651,-585 651,-579 651,-579 651,-535 651,-535 651,-529 657,-523 663,-523 663,-523 779,-523 779,-523 785,-523 791,-529 791,-535 791,-535 791,-579 791,-579 791,-585 785,-591 779,-591\"/>\n",
       "<text text-anchor=\"start\" x=\"667.5\" y=\"-575.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">LogFare  3.31</text>\n",
       "<text text-anchor=\"start\" x=\"681.5\" y=\"-560.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.31</text>\n",
       "<text text-anchor=\"start\" x=\"668\" y=\"-545.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 439</text>\n",
       "<text text-anchor=\"start\" x=\"659\" y=\"-530.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [356, 83]</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;8 -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>0&#45;&gt;8</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M614.36,-629.78C630.02,-619.24 647.47,-607.49 663.64,-596.61\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"665.62,-599.49 671.96,-591.01 661.71,-593.69 665.62,-599.49\"/>\n",
       "<text text-anchor=\"middle\" x=\"667.17\" y=\"-611.84\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>2</title>\n",
       "<path fill=\"#40a0e6\" stroke=\"black\" d=\"M254.5,-484C254.5,-484 147.5,-484 147.5,-484 141.5,-484 135.5,-478 135.5,-472 135.5,-472 135.5,-428 135.5,-428 135.5,-422 141.5,-416 147.5,-416 147.5,-416 254.5,-416 254.5,-416 260.5,-416 266.5,-422 266.5,-428 266.5,-428 266.5,-472 266.5,-472 266.5,-478 260.5,-484 254.5,-484\"/>\n",
       "<text text-anchor=\"start\" x=\"161\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age  28.5</text>\n",
       "<text text-anchor=\"start\" x=\"161.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.06</text>\n",
       "<text text-anchor=\"start\" x=\"148\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 120</text>\n",
       "<text text-anchor=\"start\" x=\"143.5\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [4, 116]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M349.64,-522.92C326.17,-511.57 299.79,-498.8 275.84,-487.21\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"277.32,-484.04 266.79,-482.84 274.27,-490.34 277.32,-484.04\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>5</title>\n",
       "<path fill=\"#fffdfb\" stroke=\"black\" d=\"M471.5,-484C471.5,-484 364.5,-484 364.5,-484 358.5,-484 352.5,-478 352.5,-472 352.5,-472 352.5,-428 352.5,-428 352.5,-422 358.5,-416 364.5,-416 364.5,-416 471.5,-416 471.5,-416 477.5,-416 483.5,-422 483.5,-428 483.5,-428 483.5,-472 483.5,-472 483.5,-478 477.5,-484 471.5,-484\"/>\n",
       "<text text-anchor=\"start\" x=\"369\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">LogFare  2.7</text>\n",
       "<text text-anchor=\"start\" x=\"383\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.5</text>\n",
       "<text text-anchor=\"start\" x=\"365\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 109</text>\n",
       "<text text-anchor=\"start\" x=\"360.5\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [55, 54]</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M418,-522.78C418,-513.69 418,-503.7 418,-494.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"421.5,-494.01 418,-484.01 414.5,-494.01 421.5,-494.01\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>3</title>\n",
       "<path fill=\"#45a3e7\" stroke=\"black\" d=\"M110,-368.5C110,-368.5 12,-368.5 12,-368.5 6,-368.5 0,-362.5 0,-356.5 0,-356.5 0,-327.5 0,-327.5 0,-321.5 6,-315.5 12,-315.5 12,-315.5 110,-315.5 110,-315.5 116,-315.5 122,-321.5 122,-327.5 122,-327.5 122,-356.5 122,-356.5 122,-362.5 116,-368.5 110,-368.5\"/>\n",
       "<text text-anchor=\"start\" x=\"21.5\" y=\"-353.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.11</text>\n",
       "<text text-anchor=\"start\" x=\"12.5\" y=\"-338.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 53</text>\n",
       "<text text-anchor=\"start\" x=\"8\" y=\"-323.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [3, 50]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M157.09,-415.75C139.86,-402.71 120.17,-387.8 103.12,-374.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"105.07,-371.98 94.98,-368.73 100.84,-377.56 105.07,-371.98\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>4</title>\n",
       "<path fill=\"#3c9ee5\" stroke=\"black\" d=\"M250,-368.5C250,-368.5 152,-368.5 152,-368.5 146,-368.5 140,-362.5 140,-356.5 140,-356.5 140,-327.5 140,-327.5 140,-321.5 146,-315.5 152,-315.5 152,-315.5 250,-315.5 250,-315.5 256,-315.5 262,-321.5 262,-327.5 262,-327.5 262,-356.5 262,-356.5 262,-362.5 256,-368.5 250,-368.5\"/>\n",
       "<text text-anchor=\"start\" x=\"161.5\" y=\"-353.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.03</text>\n",
       "<text text-anchor=\"start\" x=\"152.5\" y=\"-338.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 67</text>\n",
       "<text text-anchor=\"start\" x=\"148\" y=\"-323.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [1, 66]</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M201,-415.75C201,-404.01 201,-390.76 201,-378.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"204.5,-378.73 201,-368.73 197.5,-378.73 204.5,-378.73\"/>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>6</title>\n",
       "<path fill=\"#cbe5f8\" stroke=\"black\" d=\"M399.5,-368.5C399.5,-368.5 292.5,-368.5 292.5,-368.5 286.5,-368.5 280.5,-362.5 280.5,-356.5 280.5,-356.5 280.5,-327.5 280.5,-327.5 280.5,-321.5 286.5,-315.5 292.5,-315.5 292.5,-315.5 399.5,-315.5 399.5,-315.5 405.5,-315.5 411.5,-321.5 411.5,-327.5 411.5,-327.5 411.5,-356.5 411.5,-356.5 411.5,-362.5 405.5,-368.5 399.5,-368.5\"/>\n",
       "<text text-anchor=\"start\" x=\"306.5\" y=\"-353.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.49</text>\n",
       "<text text-anchor=\"start\" x=\"297.5\" y=\"-338.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 59</text>\n",
       "<text text-anchor=\"start\" x=\"288.5\" y=\"-323.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [25, 34]</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>5&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M395.42,-415.75C387.04,-403.42 377.53,-389.42 369.11,-377.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"371.99,-375.04 363.48,-368.73 366.2,-378.97 371.99,-375.04\"/>\n",
       "</g>\n",
       "<!-- 7 -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>7</title>\n",
       "<path fill=\"#f6d5bd\" stroke=\"black\" d=\"M548.5,-368.5C548.5,-368.5 441.5,-368.5 441.5,-368.5 435.5,-368.5 429.5,-362.5 429.5,-356.5 429.5,-356.5 429.5,-327.5 429.5,-327.5 429.5,-321.5 435.5,-315.5 441.5,-315.5 441.5,-315.5 548.5,-315.5 548.5,-315.5 554.5,-315.5 560.5,-321.5 560.5,-327.5 560.5,-327.5 560.5,-356.5 560.5,-356.5 560.5,-362.5 554.5,-368.5 548.5,-368.5\"/>\n",
       "<text text-anchor=\"start\" x=\"455.5\" y=\"-353.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n",
       "<text text-anchor=\"start\" x=\"446.5\" y=\"-338.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\n",
       "<text text-anchor=\"start\" x=\"437.5\" y=\"-323.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [30, 20]</text>\n",
       "</g>\n",
       "<!-- 5&#45;&gt;7 -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>5&#45;&gt;7</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M442.15,-415.75C451.11,-403.42 461.28,-389.42 470.29,-377.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"473.26,-378.88 476.31,-368.73 467.6,-374.76 473.26,-378.88\"/>\n",
       "</g>\n",
       "<!-- 9 -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>9</title>\n",
       "<path fill=\"#e99659\" stroke=\"black\" d=\"M779,-484C779,-484 663,-484 663,-484 657,-484 651,-478 651,-472 651,-472 651,-428 651,-428 651,-422 657,-416 663,-416 663,-416 779,-416 779,-416 785,-416 791,-422 791,-428 791,-428 791,-472 791,-472 791,-478 785,-484 779,-484\"/>\n",
       "<text text-anchor=\"start\" x=\"681\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age  20.5</text>\n",
       "<text text-anchor=\"start\" x=\"681.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.24</text>\n",
       "<text text-anchor=\"start\" x=\"668\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 320</text>\n",
       "<text text-anchor=\"start\" x=\"659\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [275, 45]</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;9 -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>8&#45;&gt;9</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M721,-522.78C721,-513.69 721,-503.7 721,-494.15\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"724.5,-494.01 721,-484.01 717.5,-494.01 724.5,-494.01\"/>\n",
       "</g>\n",
       "<!-- 18 -->\n",
       "<g id=\"node19\" class=\"node\">\n",
       "<title>18</title>\n",
       "<path fill=\"#f1bc96\" stroke=\"black\" d=\"M1005.5,-484C1005.5,-484 898.5,-484 898.5,-484 892.5,-484 886.5,-478 886.5,-472 886.5,-472 886.5,-428 886.5,-428 886.5,-422 892.5,-416 898.5,-416 898.5,-416 1005.5,-416 1005.5,-416 1011.5,-416 1017.5,-422 1017.5,-428 1017.5,-428 1017.5,-472 1017.5,-472 1017.5,-478 1011.5,-484 1005.5,-484\"/>\n",
       "<text text-anchor=\"start\" x=\"910\" y=\"-468.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">SibSp  0.5</text>\n",
       "<text text-anchor=\"start\" x=\"912.5\" y=\"-453.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.43</text>\n",
       "<text text-anchor=\"start\" x=\"899\" y=\"-438.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 119</text>\n",
       "<text text-anchor=\"start\" x=\"894.5\" y=\"-423.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [81, 38]</text>\n",
       "</g>\n",
       "<!-- 8&#45;&gt;18 -->\n",
       "<g id=\"edge18\" class=\"edge\">\n",
       "<title>8&#45;&gt;18</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M791.25,-524.07C818.44,-511.71 849.6,-497.54 877.21,-485\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"878.77,-488.13 886.42,-480.81 875.87,-481.76 878.77,-488.13\"/>\n",
       "</g>\n",
       "<!-- 10 -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>10</title>\n",
       "<path fill=\"#f1b992\" stroke=\"black\" d=\"M697.5,-368.5C697.5,-368.5 590.5,-368.5 590.5,-368.5 584.5,-368.5 578.5,-362.5 578.5,-356.5 578.5,-356.5 578.5,-327.5 578.5,-327.5 578.5,-321.5 584.5,-315.5 590.5,-315.5 590.5,-315.5 697.5,-315.5 697.5,-315.5 703.5,-315.5 709.5,-321.5 709.5,-327.5 709.5,-327.5 709.5,-356.5 709.5,-356.5 709.5,-362.5 703.5,-368.5 697.5,-368.5\"/>\n",
       "<text text-anchor=\"start\" x=\"604.5\" y=\"-353.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.43</text>\n",
       "<text text-anchor=\"start\" x=\"595.5\" y=\"-338.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 55</text>\n",
       "<text text-anchor=\"start\" x=\"586.5\" y=\"-323.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [38, 17]</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;10 -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>9&#45;&gt;10</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M696.85,-415.75C687.89,-403.42 677.72,-389.42 668.71,-377.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"671.4,-374.76 662.69,-368.73 665.74,-378.88 671.4,-374.76\"/>\n",
       "</g>\n",
       "<!-- 11 -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>11</title>\n",
       "<path fill=\"#e89050\" stroke=\"black\" d=\"M856,-376C856,-376 740,-376 740,-376 734,-376 728,-370 728,-364 728,-364 728,-320 728,-320 728,-314 734,-308 740,-308 740,-308 856,-308 856,-308 862,-308 868,-314 868,-320 868,-320 868,-364 868,-364 868,-370 862,-376 856,-376\"/>\n",
       "<text text-anchor=\"start\" x=\"758\" y=\"-360.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age  32.5</text>\n",
       "<text text-anchor=\"start\" x=\"758.5\" y=\"-345.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.19</text>\n",
       "<text text-anchor=\"start\" x=\"745\" y=\"-330.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 265</text>\n",
       "<text text-anchor=\"start\" x=\"736\" y=\"-315.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [237, 28]</text>\n",
       "</g>\n",
       "<!-- 9&#45;&gt;11 -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>9&#45;&gt;11</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M745.15,-415.75C752.39,-405.79 760.42,-394.73 767.99,-384.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"770.89,-386.28 773.93,-376.13 765.22,-382.16 770.89,-386.28\"/>\n",
       "</g>\n",
       "<!-- 12 -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>12</title>\n",
       "<path fill=\"#e99356\" stroke=\"black\" d=\"M781,-269C781,-269 665,-269 665,-269 659,-269 653,-263 653,-257 653,-257 653,-213 653,-213 653,-207 659,-201 665,-201 665,-201 781,-201 781,-201 787,-201 793,-207 793,-213 793,-213 793,-257 793,-257 793,-263 787,-269 781,-269\"/>\n",
       "<text text-anchor=\"start\" x=\"678.5\" y=\"-253.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">Age  24.75</text>\n",
       "<text text-anchor=\"start\" x=\"683.5\" y=\"-238.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.22</text>\n",
       "<text text-anchor=\"start\" x=\"670\" y=\"-223.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 181</text>\n",
       "<text text-anchor=\"start\" x=\"661\" y=\"-208.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [158, 23]</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;12 -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>11&#45;&gt;12</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M774.27,-307.78C767.36,-298.11 759.73,-287.43 752.52,-277.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"755.24,-275.11 746.58,-269.01 749.54,-279.18 755.24,-275.11\"/>\n",
       "</g>\n",
       "<!-- 17 -->\n",
       "<g id=\"node18\" class=\"node\">\n",
       "<title>17</title>\n",
       "<path fill=\"#e78946\" stroke=\"black\" d=\"M921,-261.5C921,-261.5 823,-261.5 823,-261.5 817,-261.5 811,-255.5 811,-249.5 811,-249.5 811,-220.5 811,-220.5 811,-214.5 817,-208.5 823,-208.5 823,-208.5 921,-208.5 921,-208.5 927,-208.5 933,-214.5 933,-220.5 933,-220.5 933,-249.5 933,-249.5 933,-255.5 927,-261.5 921,-261.5\"/>\n",
       "<text text-anchor=\"start\" x=\"832.5\" y=\"-246.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.11</text>\n",
       "<text text-anchor=\"start\" x=\"823.5\" y=\"-231.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 84</text>\n",
       "<text text-anchor=\"start\" x=\"819\" y=\"-216.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [79, 5]</text>\n",
       "</g>\n",
       "<!-- 11&#45;&gt;17 -->\n",
       "<g id=\"edge17\" class=\"edge\">\n",
       "<title>11&#45;&gt;17</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M821.41,-307.78C829.86,-295.79 839.41,-282.24 847.92,-270.17\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"851,-271.88 853.9,-261.69 845.28,-267.84 851,-271.88\"/>\n",
       "</g>\n",
       "<!-- 13 -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>13</title>\n",
       "<path fill=\"#e88d4c\" stroke=\"black\" d=\"M704,-161C704,-161 588,-161 588,-161 582,-161 576,-155 576,-149 576,-149 576,-105 576,-105 576,-99 582,-93 588,-93 588,-93 704,-93 704,-93 710,-93 716,-99 716,-105 716,-105 716,-149 716,-149 716,-155 710,-161 704,-161\"/>\n",
       "<text text-anchor=\"start\" x=\"592.5\" y=\"-145.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">LogFare  2.18</text>\n",
       "<text text-anchor=\"start\" x=\"606.5\" y=\"-130.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.16</text>\n",
       "<text text-anchor=\"start\" x=\"593\" y=\"-115.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 114</text>\n",
       "<text text-anchor=\"start\" x=\"584\" y=\"-100.8\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [104, 10]</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;13 -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>12&#45;&gt;13</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M698.85,-200.75C691.61,-190.79 683.58,-179.73 676.01,-169.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"678.78,-167.16 670.07,-161.13 673.11,-171.28 678.78,-167.16\"/>\n",
       "</g>\n",
       "<!-- 16 -->\n",
       "<g id=\"node17\" class=\"node\">\n",
       "<title>16</title>\n",
       "<path fill=\"#eb9f69\" stroke=\"black\" d=\"M853.5,-153.5C853.5,-153.5 746.5,-153.5 746.5,-153.5 740.5,-153.5 734.5,-147.5 734.5,-141.5 734.5,-141.5 734.5,-112.5 734.5,-112.5 734.5,-106.5 740.5,-100.5 746.5,-100.5 746.5,-100.5 853.5,-100.5 853.5,-100.5 859.5,-100.5 865.5,-106.5 865.5,-112.5 865.5,-112.5 865.5,-141.5 865.5,-141.5 865.5,-147.5 859.5,-153.5 853.5,-153.5\"/>\n",
       "<text text-anchor=\"start\" x=\"760.5\" y=\"-138.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.31</text>\n",
       "<text text-anchor=\"start\" x=\"751.5\" y=\"-123.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 67</text>\n",
       "<text text-anchor=\"start\" x=\"742.5\" y=\"-108.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [54, 13]</text>\n",
       "</g>\n",
       "<!-- 12&#45;&gt;16 -->\n",
       "<g id=\"edge16\" class=\"edge\">\n",
       "<title>12&#45;&gt;16</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M747.15,-200.75C756.11,-188.42 766.28,-174.42 775.29,-162.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"778.26,-163.88 781.31,-153.73 772.6,-159.76 778.26,-163.88\"/>\n",
       "</g>\n",
       "<!-- 14 -->\n",
       "<g id=\"node15\" class=\"node\">\n",
       "<title>14</title>\n",
       "<path fill=\"#e99254\" stroke=\"black\" d=\"M625,-53.5C625,-53.5 527,-53.5 527,-53.5 521,-53.5 515,-47.5 515,-41.5 515,-41.5 515,-12.5 515,-12.5 515,-6.5 521,-0.5 527,-0.5 527,-0.5 625,-0.5 625,-0.5 631,-0.5 637,-6.5 637,-12.5 637,-12.5 637,-41.5 637,-41.5 637,-47.5 631,-53.5 625,-53.5\"/>\n",
       "<text text-anchor=\"start\" x=\"536.5\" y=\"-38.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.21</text>\n",
       "<text text-anchor=\"start\" x=\"527.5\" y=\"-23.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 50</text>\n",
       "<text text-anchor=\"start\" x=\"523\" y=\"-8.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [44, 6]</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;14 -->\n",
       "<g id=\"edge14\" class=\"edge\">\n",
       "<title>13&#45;&gt;14</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M622.3,-92.82C615.17,-82.84 607.35,-71.89 600.19,-61.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"603.02,-59.81 594.36,-53.71 597.33,-63.88 603.02,-59.81\"/>\n",
       "</g>\n",
       "<!-- 15 -->\n",
       "<g id=\"node16\" class=\"node\">\n",
       "<title>15</title>\n",
       "<path fill=\"#e78946\" stroke=\"black\" d=\"M765,-53.5C765,-53.5 667,-53.5 667,-53.5 661,-53.5 655,-47.5 655,-41.5 655,-41.5 655,-12.5 655,-12.5 655,-6.5 661,-0.5 667,-0.5 667,-0.5 765,-0.5 765,-0.5 771,-0.5 777,-6.5 777,-12.5 777,-12.5 777,-41.5 777,-41.5 777,-47.5 771,-53.5 765,-53.5\"/>\n",
       "<text text-anchor=\"start\" x=\"676.5\" y=\"-38.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.12</text>\n",
       "<text text-anchor=\"start\" x=\"667.5\" y=\"-23.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 64</text>\n",
       "<text text-anchor=\"start\" x=\"663\" y=\"-8.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [60, 4]</text>\n",
       "</g>\n",
       "<!-- 13&#45;&gt;15 -->\n",
       "<g id=\"edge15\" class=\"edge\">\n",
       "<title>13&#45;&gt;15</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M669.7,-92.82C676.83,-82.84 684.65,-71.89 691.81,-61.86\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"694.67,-63.88 697.64,-53.71 688.98,-59.81 694.67,-63.88\"/>\n",
       "</g>\n",
       "<!-- 19 -->\n",
       "<g id=\"node20\" class=\"node\">\n",
       "<title>19</title>\n",
       "<path fill=\"#f6d5bd\" stroke=\"black\" d=\"M1005.5,-368.5C1005.5,-368.5 898.5,-368.5 898.5,-368.5 892.5,-368.5 886.5,-362.5 886.5,-356.5 886.5,-356.5 886.5,-327.5 886.5,-327.5 886.5,-321.5 892.5,-315.5 898.5,-315.5 898.5,-315.5 1005.5,-315.5 1005.5,-315.5 1011.5,-315.5 1017.5,-321.5 1017.5,-327.5 1017.5,-327.5 1017.5,-356.5 1017.5,-356.5 1017.5,-362.5 1011.5,-368.5 1005.5,-368.5\"/>\n",
       "<text text-anchor=\"start\" x=\"912.5\" y=\"-353.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.48</text>\n",
       "<text text-anchor=\"start\" x=\"903.5\" y=\"-338.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 60</text>\n",
       "<text text-anchor=\"start\" x=\"894.5\" y=\"-323.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [36, 24]</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;19 -->\n",
       "<g id=\"edge19\" class=\"edge\">\n",
       "<title>18&#45;&gt;19</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M952,-415.75C952,-404.01 952,-390.76 952,-378.82\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"955.5,-378.73 952,-368.73 948.5,-378.73 955.5,-378.73\"/>\n",
       "</g>\n",
       "<!-- 20 -->\n",
       "<g id=\"node21\" class=\"node\">\n",
       "<title>20</title>\n",
       "<path fill=\"#eda877\" stroke=\"black\" d=\"M1154.5,-368.5C1154.5,-368.5 1047.5,-368.5 1047.5,-368.5 1041.5,-368.5 1035.5,-362.5 1035.5,-356.5 1035.5,-356.5 1035.5,-327.5 1035.5,-327.5 1035.5,-321.5 1041.5,-315.5 1047.5,-315.5 1047.5,-315.5 1154.5,-315.5 1154.5,-315.5 1160.5,-315.5 1166.5,-321.5 1166.5,-327.5 1166.5,-327.5 1166.5,-356.5 1166.5,-356.5 1166.5,-362.5 1160.5,-368.5 1154.5,-368.5\"/>\n",
       "<text text-anchor=\"start\" x=\"1061.5\" y=\"-353.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">gini = 0.36</text>\n",
       "<text text-anchor=\"start\" x=\"1052.5\" y=\"-338.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">samples = 59</text>\n",
       "<text text-anchor=\"start\" x=\"1043.5\" y=\"-323.3\" font-family=\"Helvetica,sans-Serif\" font-size=\"14.00\">value = [45, 14]</text>\n",
       "</g>\n",
       "<!-- 18&#45;&gt;20 -->\n",
       "<g id=\"edge20\" class=\"edge\">\n",
       "<title>18&#45;&gt;20</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M998.74,-415.75C1017.24,-402.59 1038.41,-387.53 1056.67,-374.54\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"1058.71,-377.38 1064.83,-368.73 1054.65,-371.68 1058.71,-377.38\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.sources.Source>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = DecisionTreeClassifier(min_samples_leaf=50)\n",
    "m.fit(trn_xs, trn_y)\n",
    "draw_tree(m, trn_xs, size=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18385650224215247"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_absolute_error(val_y, m.predict(val_xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like this is an improvement, although again it's a bit hard to tell with small datasets like this. Let's try submitting it to Kaggle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_df[cats] = tst_df[cats].apply(lambda x: x.cat.codes)\n",
    "tst_xs,_ = xs_y(tst_df)\n",
    "\n",
    "def subm(preds, suff):\n",
    "    tst_df['Survived'] = preds\n",
    "    sub_df = tst_df[['PassengerId','Survived']]\n",
    "    sub_df.to_csv(f'sub-{suff}.csv', index=False)\n",
    "\n",
    "subm(m.predict(tst_xs), 'tree')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I submitted this, I got a score of 0.765, which isn't as good as our linear models or most of our neural nets, but it's pretty close to those results.\n",
    "\n",
    "Hopefully you can now see why we didn't really need to create dummy variables, but instead just converted the labels into numbers using some (potentially arbitary) ordering of categories. For instance, here's how the first few items of `Embarked` are labeled:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    S\n",
       "1    C\n",
       "2    S\n",
       "3    S\n",
       "4    S\n",
       "Name: Embarked, dtype: category\n",
       "Categories (3, object): ['C', 'Q', 'S']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Embarked.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...resulting in these integer codes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    0\n",
       "2    2\n",
       "3    2\n",
       "4    2\n",
       "dtype: int8"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Embarked.cat.codes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let's say we wanted to split into \"C\" in one group, vs \"Q\" or \"S\" in the other group. Then we just have to split on codes `<=0` (since `C` is mapped to category `0`). Note that if we wanted to split into \"Q\" in one group, we'd need to use two binary splits, first to separate \"C\" from \"Q\" and \"S\", and then a second split to separate \"Q\" from \"S\". For this reason, sometimes it can still be helpful to use dummy variables for categorical variables with few levels (like this one).\n",
    "\n",
    "In practice, I often use dummy variables for <4 levels, and numeric codes for >=4 levels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The random forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't make the decision tree much bigger than the example above, since some leaf nodes already have only 50 rows in them. That's not a lot of data to make a prediction.\n",
    "\n",
    "So how could we use bigger trees? One big insight came from Leo Breiman: what if we create lots of bigger trees, and take the average of their predictions? Taking the average prediction of a bunch of models in this way is known as [bagging](https://link.springer.com/article/10.1007/BF00058655).\n",
    "\n",
    "The idea is that we want each model's predictions in the averaged ensemble to be uncorrelated with each other model. That way, if we average the predictions, the average will be equal to the true target value -- that's because the average of lots of uncorrelated random errors is zero. That's quite an amazing insight!\n",
    "\n",
    "One way we can create a bunch of uncorrelated models is to train each of them on a different random subset of the data. Here's how we can create a tree on a random subset of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree(prop=0.75):\n",
    "    n = len(trn_y)\n",
    "    idxs = random.choice(n, int(n*prop))\n",
    "    return DecisionTreeClassifier(min_samples_leaf=5).fit(trn_xs.iloc[idxs], trn_y.iloc[idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create as many trees as we want:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = [get_tree() for t in range(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our prediction will be the average of these trees' predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2272645739910314"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_probs = [t.predict(val_xs) for t in trees]\n",
    "avg_probs = np.stack(all_probs).mean(0)\n",
    "\n",
    "mean_absolute_error(val_y, avg_probs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nearly identical to what `sklearn`'s `RandomForestClassifier` does. The main extra piece in a \"real\" random forest is that as well as choosing a random sample of data for each tree, it also picks a random subset of columns for each split. Here's how we repeat the above process with a random forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18834080717488788"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(100, min_samples_leaf=5)\n",
    "rf.fit(trn_xs, trn_y);\n",
    "mean_absolute_error(val_y, rf.predict(val_xs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can submit that to Kaggle too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subm(rf.predict(tst_xs), 'rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found that gave nearly an identical result as our single tree (which, in turn, was slightly lower than our linear and neural net models in the previous notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One particularly nice feature of random forests is they can tell us which independent variables were the most important in the model, using `feature_importances_`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame(dict(cols=trn_xs.columns, imp=m.feature_importances_)).plot('cols', 'imp', 'barh');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that `Sex` is by far the most important predictor, with `Pclass` a distant second, and `LogFare` and `Age` behind that. In datasets with many columns, I generally recommend creating a feature importance plot as soon as possible, in order to find which columns are worth studying more closely. (Note also that we didn't really need to take the `log()` of `Fare`, since random forests only care about order, and `log()` doesn't change the order -- we only did it to make our graphs earlier easier to read.)\n",
    "\n",
    "For details about deriving and understanding feature importances, and the many other important diagnostic tools provided by random forests, take a look at [chapter 8](https://github.com/fastai/fastbook/blob/master/08_collab.ipynb) of [our book](https://www.amazon.com/Deep-Learning-Coders-fastai-PyTorch/dp/1492045527)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So what can we take away from all this?\n",
    "\n",
    "I think the first thing I'd note from this is that, clearly, more complex models aren't always better. Our \"OneR\" model, consisting of a single binary split, was nearly as good as our more complex models. Perhaps in practice a simple model like this might be much easier to use, and could be worth considering. Our random forest wasn't an improvement on the single decision tree at all.\n",
    "\n",
    "So we should always be careful to benchmark simple models, as see if they're good enough for our needs. In practice, you will often find that simple models will have trouble providing adequate accuracy for more complex tasks, such as recommendation systems, NLP, computer vision, or multivariate time series. But there's no need to guess -- it's so easy to try a few different models, there's no reason not to give the simpler ones a go too!\n",
    "\n",
    "Another thing I think we can take away is that random forests aren't actually that complicated at all. We were able to implement the key features of them in a notebook quite quickly. And they aren't sensitive to issues like normalization, interactions, or non-linear transformations, which make them extremely easy to work with, and hard to mess up!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you found this notebook useful, please remember to click the little up-arrow at the top to upvote it, since I like to know when people have found my work useful, and it helps others find it too. (BTW, be sure you're looking at my [original notebook here](https://www.kaggle.com/jhoward/how-random-forests-work) when you do that, and are not on your own copy of it, otherwise your upvote won't get counted!) And if you have any questions or comments, please pop them below -- I read every comment I receive!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
